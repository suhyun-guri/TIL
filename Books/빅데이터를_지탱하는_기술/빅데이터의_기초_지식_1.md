<span style='color:gray'> *본 내용은 `빅데이터를 지탱하는 기술 (니시다 케이스케)` 책을 정리한 내용입니다.* <span>
<span style='color:gray'> *Chapter 1 빅데이터의 기초 지식 1-1 ~ 1-2* <span>  <br>
<img src=https://velog.velcdn.com/images/suhyun-guri/post/09cb1adf-fd87-4be0-bbd1-7ecba34241a3/image.jpg width=350>
<hr />

# 1-1 빅데이터의 정착

“빅데이터”라는 단어를 자주 접하게 된 것은 2011년 후반에서 2012년에 걸쳐 많은 기업들이 데이터 처리에 분산 시스템을 도입하기 시작했을 무렵이다. 

빅데이터의 취급이 어려운 이유는 크게 두 가지이다.
1. 데이터의 분석 방법을 모른다
2. 데이터 처리에 수고와 시간이 걸린다.

그러나 이 두 가지를 갖추고 나서야 비로소 가치 있는 정보를 얻을 수 있다.

### 빅데이터 기술의 요구 - Hadoop, NoSQL

빅데이터의 기술로 가장 먼저 예로 들 수 있는 것이 Hadoop과 NoSQL이다.

웹 서버 등에서 생성된 데이터는 처음에는 RDB와 NoSQL 등의 텍스트 데이터에 저장된다. 그 후 모든 데이터가 Hadoop으로 모이고, 거기서 대규모 데이터 처리가 실행된다.

데이터가 많아지면서 전통적인 관계형 데이터베이스(RDB)로는 취급할 수 없을 만큼 쌓이게 되었다. 그래서 Hadoop과 NoSQL이 각각 다른 요구를 충족시키기 위해 나타났다.

> NoSQL이란?
- **No SQL, Not Only SQL**
  - 단순히 기존 관계형 DBMS가 갖고 있는 특성뿐만 아니라 다른 특성들을 부가적으로 지원한다는 것을 의미
  - 기존의 관계형 데이터베이스보다 더 융통성있는 데이터 모델을 사용하고 데이터의 저장 및 검색을 위한 특화된 매커니즘을 제공한다. 단순 검색 및 추가 작업에 있어서 매우 최적화된 키-값 저장 기법을 사용하여 응답속도나 처리 효율 등에 있어서 뛰어난 성능을 나타낸다.
  - 즉, NoSQL은 초고용량 데이터 처리 등 성능에 특화된 목적을 위해 비관계형 데이터 저장소에 비구조적인 데이터를 저장하기 위한 분산 저장 시스템이다.
[[참고자료] Samsung SDS - NoSQL이란 무엇인가?](https://www.samsungsds.com/kr/insights/1232564_4627.html)

**Hadoop**

- Hadoop은 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 시스템이다.
- 방대한 데이터를 저장해둘 스토리지와 데이터를 순차적으로 처리할 수 있는 구조가 필요하다. 이를 위해서는 수백 수천 대의 컴퓨터가 이용되어야 하며 이를 관리하는 것이 Hadoop이다.
- 구글에서 개발된 분산 처리 프레임워크인 MapReduce를 참고하여 제작되었다.
- SQL과 같은 쿼리 언어를 Hadoop에서 실행하기 위한 소프트웨어로 Hive가 개발되었다. Hive의 도입으로 프로그래밍 없이 데이터를 집계할 수 있게 함으로써 많은 사람이 사용할 수 있게 되었다.

**NoSQL 데이터베이스**

- NoSQL은 전통적인 RDB의 제약을 제거하는 것을 목표로 한 데이터베이스의 총칭이다.
- 다양한 종류가 있다. 다수의 키와 값을 관련지어 저장하는 `key-value store`, JSON과 같은 복잡한 데이터 구조를 저장하는 `document store`, 여러 키를 사용하여 높은 확장성을 제공하는 `wide-column store` 등이 대표적이다.
- RDB보다 고속의 읽기, 쓰기가 가능하고 분산 처리에 뛰어나다는 특징을 갖추고 있다.
- 모여진 데이터를 나중에 집계하는 것이 목적인 Hadoop과 다르게 NoSQL은 애플리케이션에서 온라인으로 접속하는 데이터베이스이다.

**Hadoop + NoSQL 조합**

- NoSQL 데이터베이스에 기록하고 Hadoop으로 분산 처리하기
- **방대한 규모로 계속 증가하는 데이터에 대해 현실적인 비용으로 데이터를 처리**할 수 있게 되었다.

# 1-2 빅데이터 시대의 데이터 분석 기반

빅데이터 기술이 기존의 데이터 웨어하우스와 다른 점은 다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 점이다. 이 책에서 다루는 ‘빅데이터 기술’이란 분산 시스템을 활용하면서 데이터를 순차적으로 가공해나가는 일련의 구조다.

### 데이터 파이프라인
데이터 파이프라인은 일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템을 말한다.

빅데이터의 데이터 파이프라인은 어디에서 데이터를 수집하여 무엇을 실현하고 싶은 지에 따라 변화한다. 처음에는 간단한 구성으로도 끝나지만, 하고 싶은 일이 증가함에 따라 시스템은 점차 복잡해지고 그것을 어떻게 조합시킬지가 문제가 된다.

### 데이터 수집

데이터 파이프라인은 데이터 수집부터 시작한다. 데이터는 여러 장소에서 발생하고 각각 다른 형태를 보인다. 또한 서로 다른 기술로 데이터를 전송한다.

데이터 전송(data transfer)의 방법은 크게 두 가지가 있다.

1. 벌크(bulk) 형
2. 스트리밍(streaming) 형

![빅데이터를 위한 데이터 파이프라인](https://velog.velcdn.com/images/suhyun-guri/post/4497a4dc-0517-41b1-aea9-98ba7572bc26/image.jpg)

벌크 형은 이미 어딘가에 존재하는 데이터를 정리해 추출하는 방법으로, 데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는 데에 사용한다. 

스트리밍 형은 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법으로 모바일 애플리케이션과 임베디드 장비 등에서 널리 데이터를 수집하는 데 사용된다.

### 스트림 처리와 배치 처리
- **스트림 처리(stream processing)** : 모바일 애플리케이션 등에서 데이터를 실시간으로 처리하는 것, 장기적인 데이터 분석에는 적합하지 않은 문제
- **배치 처리(batch processing)** : 어느 정도 정리된 데이터를 효율적으로 가공하는 것, (장기적인 데이터 분석을 목적으로) 대량의 데이터를 저장하고 처리하는 데 적합

### 분산 스토리지
수집된 데이터는 분산 스토리지(distribute storage)’에 저장된다.
분산 스토리지 : 여러 컴퓨터와 디스크로부터 구성된 스토리지 시스템

데이터를 저장하는 방법 

1. 객체 스토리지 : 한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장, 클라우드 서비스인 Amazon S3 등이 유명
2. NoSQL 데이터베이스 : 애플리케이션에서 많은 데이터를 읽고 쓰는 데에 있어서 성능이 우수, 단 나중에 데이터 용량을 얼마든지 늘릴 수 있는 확장성이 높은 제품을 선택해야 함

### 분산 데이터 처리

분산 스토리지에 저장된 데이터를 처리하는 데는 분산 데이터 처리의 프레임워크가 필요하다.

MapReduce가 사용되어진 것이 바로 이 부분, 데이터양과 처리의 내용에 따라 많은 컴퓨터 자원이 필요하게 된다.

분산 데이터 처리의 주 역할은 나중에 분석하기 쉽도록 데이터를 가공해서 그 결과를 외부 데이터베이스에 저장하는 것

빅데이터를 SQL로 집계할 때 두 가지 방법

1. 쿼리 엔진을 도입 : Hive, 현재는 Hive보다도 고속인 대화형 쿼리 엔진도 개발되었다.
2. 외부의 데이터 웨어하우스 제품을 이용 : 분산 스토리지에서 추출한 데이터를 데이터 웨어하우스에 적합한 형식으로 변환해야 한다. → ETL 프로세스 (데이터를 추출(extract), 가공(transform), 데이터 웨어하우스에 로드(load))

### 워크플로 관리

전체 데이터 파이프라인의 동작을 관리하기 위해서 ‘워크플로 관리’ 기술을 사용한다.

매일 정해진 시간에 배치 처리를 스케줄대로 실행하고, 오류가 발생한 경우에는 관리자에게 통지하는 목적으로 사용

데이터 파이프라인이 복잡해짐에 따라 그것을 한 곳에서 제어하지 않으면 전체의 움직임을 파악하기가 어렵다. 오류 발생 시의 처리와 다시 처리하기 위한 기능을 만드는 것을 빼놓아서는 안된다.

### 데이터 웨어하우스와 데이터 마트

![](https://velog.velcdn.com/images/suhyun-guri/post/f68a177e-0047-44e2-a962-597da0771d15/image.jpg)

데이터 웨어하우스는 대량의 데이터를 장기 보존하는 것에 최적화되어 있다. 정리된 데이터를 한 번에 전송하는 것은 뛰어나지만, 소량의 데이터를 자주 쓰고 읽는 데는 적합하지 않다.

전형적인 사용 방법 - 업무 시스템에서 꺼낸 데이터를 하루가 끝날 때 정리하여 쓰고, 이를 야간에 집계해서 보고서를 작성

- 데이터 소스(data source) : 업무 시스템을 위한 RDB나 로그 등을 저장하는 파일 서버
- ETL 프로세스 : 데이터 소스에 존재하는 raw 데이터를 추출하고 필요에 따라 가공한 후 데이터 웨어하우스에 저장하기까지의 흐름

데이터 웨어하우스는 중요한 데이터 처리에 사용되기 때문에 함부로 사용해 시스템 과부하를 초래하면 안된다. 따라서 데이터 분석과 같은 목적에 사용하는 경우에는 데이터 웨어하우스에서 필요한 데이터만을 추출하여 **데이터 마트(data mart)**를 구축한다. 데이터 마트는 BI 도구와 조합시키는 형태로 데이터를 시각화하는 데에도 사용된다.

데이터 웨어하우스, 데이터 마트 모두 SQL로 데이터를 집계한다. 

→ 먼저 테이블 설계를 제대로 정한 후에 데이터를 투입한다. 특히 BI 도구로 데이터를 볼 경우에는 미리 시각화에 적합한 형태로 테이블을 준비해야 한다.

### 데이터 레이크

: 모든 데이터를 원래의 형태로 축적해두고 나중에 그것을 필요에 따라 가공하기 위해 데이터를 축적해 놓는 곳

![](https://velog.velcdn.com/images/suhyun-guri/post/f3674c99-87ee-427e-9177-202985d86cff/image.jpg)

구체적으로는 임의의 데이터를 저장할 수 있는 분산 스토리지가 데이터 레이크로 이용된다.

대부분의 경우는 CSV나 JSON 등 범용적인 텍스트 형식이 사용된다.

**데이터 레이크와 데이터 마트**

데이터 레이크는 단순한 스토리지므로 이것만으로 데이터를 가공할 수 없다. 그래서 사용되는 것이 MapReduce 등의 분산 데이터 처리 기술이다.

데이터 분석에 필요한 데이터를 가공, 집계하고, 이를 데이터 마트로 추출한 후에는 데이터 웨어하우스의 경우처럼 데이터 분석을 진행할 수 있다.

### 데이터 엔지니어와 데이터 분석가

![](https://velog.velcdn.com/images/suhyun-guri/post/e45b0626-f2db-4a4b-92b9-dc58f1aae004/image.jpg)

- 데이터 엔지니어 : 시스템의 구축 및 운용, 자동화 등을 담당
- 데이터 분석가 : 데이터에서 가치 있는 정보를 추출

### 애드 혹 분석(ad hoc analysis) 및 대시보드 도구

- 애드 혹 분석(ad hoc analysis) : 일회성 데이터 분석이라는 의미로 SQL 쿼리를 직접 작성해서 실행하거나 스프레드시트에서 그래프를 만드는 것까지 포함한 모든 수작업이 포함된다.

애드 혹 분석에서는 데이터 마트를 만들지 않은 채 데이터 레이크와 데이터 웨어하우스에 직접 연결하는 경우가 많다. 

수작업으로 정기적으로 그래프와 보고서를 만들고 싶을 때 도입하는 것이 대시보드 도구다.

대시보드 도구는 데이터 마트가 없어도 동작하도록 설계되어 있어 설정한 스케줄에 따라 데이터 레이크와 데이터 웨어하우스에 접속해 쿼리를 실행하고 그 결과로부터 그래프를 생성한다.

### 데이터 마트와 워크플로 관리

복잡한 데이터 분석에서는 먼저 데이터 마트를 구축한 후에 분석하거나 시각화하도록 한다.

시각화에 BI 도구를 사용할 경우는 집계 속도를 높이기 위해 데이터 마트가 거의 필수적이다. 데이터 마트 구축은 배치 처리로 자동화되는 경우가 많기 때문에 그 실행 관리를 위해 워크플로 관리 도구를 사용한다.

데이터 처리를 자동화해서 장기적으로 운용해 나가기 위해서는 안정된 워크플로 관리가 필수적이다.

### 데이터를 수집하는 목적
**데이터 검색**

- 대량의 데이터 중에서 조건에 맞는 것을 찾고 싶은 경우
- 언제 무엇이 필요할지조차도 모르기 때문에, 시스템 로그 및 고객의 행동 이력 등 발생하는 모든 데이터를 취득해 놓도록 한다.
- 필요할 때 신속하게 검색할 수 있어야 하므로 시스템에는 실시간 데이터 처리나 검색 엔진을 사용하여 키워드를 찾는 기능이 필요하다.

**데이터 가공**
- 업무 시스템의 일부로서 데이터 처리 결과를 이용하고 싶은 경우
- 이 경우 목적이 명확하기 때문에 필요한 데이터를 계획적으로 모아 데이터 파이프라인을 설계한다.
- 데이터 가공에는 자동화가 필수적이다. 워크플로 관리를 도입하여 꼼꼼하게 테스트를 반복적으로 실행해서 시스템을 구축한다. 시스템 개발 영역에 해당된다.

**데이터 시각화**
- 데이터를 시각적으로 봄으로써 앞으로의 상황을 예측해 의사 결정에 도움이 되도록 하는 경우
- 데이터 시각화는 시행착오의 연속이며, 확실한 해답은 없다.
- 임의의 분석 환경을 갖추고 여러 번 데이터 집계를 반복한다. 고속화를 위해 데이터 마트도 필요하다.
- 또한 집계 결과를 대시보드에 정리해서 계속 변화를 감시하고 싶을 때도 데이터 시각화는 필요하다.

### 확증적 데이터 분석과 탐색적 데이터 분석

- 확증적 데이터 분석(confirmatory data analysis) : 가설을 세우고 그것을 검증하는 것, 통계학적 모델링에 의한 데이터 분석

- 탐색적 데이터 분석(exploratory data analysis) : 데이터를 보면서 그 의미를 읽어내려고 하는 것, 데이터를 시각화하여 사람의 힘에 의한 데이터 분석
