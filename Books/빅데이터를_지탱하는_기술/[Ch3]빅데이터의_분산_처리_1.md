<span style='color:gray'> *본 내용은 `빅데이터를 지탱하는 기술 (니시다 케이스케)` 책을 정리한 내용입니다.* <span>
<span style='color:gray'> *Chapter 3 빅데이터의 분산 처리 3-1* <span> <br>
<img src=https://velog.velcdn.com/images/suhyun-guri/post/09cb1adf-fd87-4be0-bbd1-7ecba34241a3/image.jpg width=350>
<hr />

# 3-1 대규모 분산 처리의 프레임워크

## 구조화 데이터와 비구조화 데이터

구조화된 데이터(structured data) : 스키마가 명확하게 정의된 데이터

> 스키마(schema) : 테이블의 칼럼 명과 데이터형, 테이블 간의 관계 등을 스키마로 정한다.
> 

비구조화 데이터(unstructed data) : 스키마가 없는 데이터, SQL로 제대로 집계 불가

ex) 텍스트 데이터와 이미지, 동영상 등의 미디어 데이터 등

비구조화 데이터를 분산 스토리지 등에 저장하고 그것을 분산 시스템에서 처리하는 것이 데이터 레이크의 개념이다. 데이터를 가공하는 과정에서 스키마를 정의하고 구조화된 데이터로 변환한다.

스키마리스 데이터 : CSV, JSON, XML 등의 데이터처럼 서식은 정해져 있지만, 칼럼 수나 데이터형이 명확하지 않은 데이터

최근에는 인터넷을 주고받는 데이터로 JSON 형식을 많이 이용한다. 새로운 데이터를 다운로드할 때마다 스키마를 정하는 것은 시간과 비용이 소요되므로 JSON 그대로 저장하고 필요한 필드만을 추출하는 것이 간단하다. 원래 데이터가 보존되어 있으면, 나중에 얼마든지 추가 정보를 꺼낼 수 있다.

### 데이터 구조화의 파이프라인

각 데이터 소스에서 수집된 비구조화 데이터 또는 스키마리스 데이터는 처음에 분산 스토리지에 보존된다. 여기에는 웹 서버의 로그 파일과 업무용 데이터베이스에서 추출한 마스터 데이터 등이 포함된다.

일반적으로 구조화 데이터는 데이터의 압축률을 높이기 위해 열 지향 스토리지로 저장한다. 

- MPP 데이터 베이스로 전송하거나 Hadoop 상에서 열 지향 스토리지 형식으로 변환

구조화 데이터 중 시간에 따라 증가하는 데이터를 팩트 테이블, 그에 따르 부속 데이터를 디멘전 테이블로 취급한다.

### 열 지향 스토리지의 작성

Hadoop에서는 사용자가 직접 열 지향 스토리지의 형식을 선택하고 자신이 좋아하는 쿼리 엔진에서 그것을 집계할 수 있다.

- Apache ORC : 구조화 데이터를 위한 열 지향 스토리지, 처음에 스키마를 정한 후 데이터를 저장
- Apache Parquet : 스키마리스에 가까운 데이터 구조로 JSON같은 뒤얽힌 데이터도 그대로 저장

비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환하는 과정에서는 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비된다. 그래서 사용하는 것이 Hadoop과 Spark 등의 분산 처리 프레임워크다.

## Hadoop

Hadoop은 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체다.

Hadoop의 기본 구성 요소는 분산 파일 시스템인 HDFS(Hadoop Distributed File System), 리소스 관리자인 YARN(Yet Another Resource Negotiator) 그리고 분산 데이터 처리의 기반인 MapReduce이다.

모든 분산 시스템이 Hadoop에 의존하는 것이 아니라, Hadoop을 일부만 사용하거나 혹은 전혀 이용하지 않는 구성도 있다. 다양한 소프트웨어 중에서 자신에게 맞는 것을 선택하고 그것들을 조합함으로써 시스템을 구성하는 것이 Hadoop을 중심으로 하는 데이터 처리의 특징이다.

### 분산 파일 시스템과 리소스 관리자 (HDFS, YARN)

- 분산 파일 시스템, HDFS
    - Hadoop에서 처리되는 데이터 대부분은 HDFS에 저장된다.
    - 이는 네트워크에 연결된 파일 서버와 같은 존재이지만, 다수의 컴퓨터에 파일을 복사하여 중복성을 높인다는 특징이 있다.
- 리소스 관리자, YARN
    - CPU나 메모리 등의 계산 리소스는 YARN에 의해 관리된다.
    - 애플리케이션이 사용하는 CPU 코어와 메모리를 컨테이너라 불리는 단위로 관리한다.
    - Hadoop에서 분산 애플리케이션을 실행하면 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당한다.
    - 애플리케이션마다 실행의 우선순위를 결정할 수 있다. 우선되는 작업부터 실행함으로써 한정된 리소스를 낭비 없이 활용하면서 데이터 처리를 진행하는 것이 가능하다.

### 분산 데이터 처리 및 쿼리 엔진 (MapReduce, Hive)

- 분산 데이터 처리, MapReduce
    - YARN 상에서 동작하는 분산 애플리케이션 중 하나. 분산 시스템에서 데이터 처리를 실행
    - 임의의 자바 프로그램을 실행시킬 수 있기 때문에 비구조화 데이터 가공에 적합
    - 대량의 데이터를 배치 처리하기 위한 시스템으로 작은 프로그램에는 실행하면 오버헤드가 너무 크기 때문에 적합하지 않다.
- 쿼리 엔진, Apache Hive
    - 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어로 개발되었다.
    - MapReduce와 마찬가지로 시간이 걸리는 배치 처리에는 적합하나, 애드 혹 쿼리를 여러 번 실행하는 데는 부적합하다.

### Hive on Tex

Hive를 가속화하기 위해 개발된 것이 Apache Tez 다. 기존의 MapReduce를 대체할 목적으로 개발되었으며 MapReduce에 있던 몇 가지 단점을 해소함으로써 고속화를 실현하고 있다.

MapReduce 프로그램에서는 1회의 MapReduce 스테이지가 끝날 때까지 다음의 처리를 할 수 없었다. Tez에서는 스테이지 종료를 기다리지 않고 처리가 끝난 데이터를 차례대로 후속 처리에 전달함으로써 쿼리 전체의 실행 시간을 단축시킨다.

### 대화형 쿼리 엔진 (Impala와 Presto)

Hive 고속화가 아닌 처음부터 대화형의 쿼리 실행만 전문으로 하는 쿼리 엔진이 개발되고 있다. 대표적으로 Apache Impala와 Presto가 있다.

대화형 쿼리 엔진은 순간 최대 속도를 높이기 위해 모든 오버헤드가 제거되어 사용할 수 있는 리소스를 최대한 활용하여 쿼리를 실행한다. 

- Hadoop에서의 쿼리 엔진
    - Hive
        - 대량의 비구조화 데이터를 가공하는 무거운 배치 처리에 높은 처리량으로 리소스를 활용하기 위해 사용
    - Impala, Presto
        - 완성한 구조화 데이터를 대화식으로 집계하고자 할 때 지연이 적은 쿼리 엔진 사용

Hadoop에서는 다수의 쿼리 엔진이 개발되어 있으며 이를 총칭해 SQL-on-Hadoop이라고 부른다.

MPP 데이터베이스만큼 오랜 역사를 가지고 있지 않기에 기능적으로 따라잡지 못한 부분도 있지만, 분산 스토리지에 저장된 데이터를 신속하게 집계할 수 있는 점에서 우수하다.

### Spark

Apache Spark는 Hadoop과는 다른 독립된 프로젝트다. MapReduce를 대체하는 존재다.

Spark의 특징은 대량의 메모리를 활용하여 고속화를 실현하는 것이다.
